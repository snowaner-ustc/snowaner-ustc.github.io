---
layout: page
title: Home
permalink: /index.html
---

We are the team of Deep Analysis Research at Alibaba Cloud.

We study Interpreting Mechanism, Knowledge Injection, Multilingual, Agents.

# Selected Blogs

- **Computer-Using Agent (CUA)** <br>
  OpenAI <br>
  A universal agent/interface to interact with the digital world. <br>
    [product](https://operator.chatgpt.com) |
    [blogpost](https://openai.com/index/computer-using-agent/) |
    [system card](https://cdn.openai.com/operator_system_card.pdf) |
    [bibtex](http://cdn.openai.com/cua/cua2025.bib)



- **Deep Research** <br>
  OpenAI <br>
  An agent that navigates and reasons over the Internet to research for you. <br>
    [product](https://chatgpt.com) |
    [blogpost](https://openai.com/index/introducing-deep-research/)
  

# Selected work

- **Computer-Using Agent (CUA)** <br>
  OpenAI <br>
  A universal agent/interface to interact with the digital world. <br>
    [product](https://operator.chatgpt.com) |
    [blogpost](https://openai.com/index/computer-using-agent/) |
    [system card](https://cdn.openai.com/operator_system_card.pdf) |
    [bibtex](http://cdn.openai.com/cua/cua2025.bib)



- **Deep Research** <br>
  OpenAI <br>
  An agent that navigates and reasons over the Internet to research for you. <br>
    [product](https://chatgpt.com) |
    [blogpost](https://openai.com/index/introducing-deep-research/) 

  
- **τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains** <br>
  Shunyu Yao, Noah Shinn, Pedram Razavi, Karthik Narasimhan <br>
  ICLR 2025 <br>
    [paper](https://arxiv.org/abs/2406.12045) |
    [repo](https://github.com/sierra-research/tau-bench) |
    [blog](https://sierra.ai/blog/benchmarking-ai-agents)

- **Language Agents: From Next-Token Prediction to Digital Automation** <br>
  Shunyu Yao <br>
  PhD Thesis <br>
    [paper](https://ysymyth.github.io/papers/Dissertation-finalized.pdf) |
    [slides](https://ysymyth.github.io/papers/fpo.pdf) |
    [talk](https://www.youtube.com/watch?v=zwfE6J2BIR4)

- **SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models** <br>
  John Yang\*, Carlos E. Jimenez\*, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, Ofir Press <br>
  NeurIPS 2024 <br>
    [paper](https://swe-agent.com/paper.pdf) |
    [repo](https://github.com/princeton-nlp/SWE-agent) |
    [tweet](https://twitter.com/jyangballin/status/1775114444370051582) |
    [project](http://www.swe-agent.com)
  

- **SWE-bench: Can Language Models Resolve Real-World Github Issues?** <br>
  Carlos E. Jimenez\*, John Yang\*, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, Karthik Narasimhan <br>
  ICLR 2024 (Oral) <br>
    [paper](https://arxiv.org/abs/2310.06770) |
    [repo](https://github.com/princeton-nlp/SWE-bench) |
    [tweet](https://twitter.com/jyangballin/status/1711822353473437953) |
    [project](http://www.swebench.com)

- **Cognitive Architectures for Language Agents** <br>
    Shunyu Yao\*, Theodore Sumers\*, Karthik Narasimhan, Thomas L. Griffiths <br>
    TMLR 2024 <br>
    [paper](https://arxiv.org/abs/2309.02427) |
    [repo](https://github.com/ysymyth/awesome-language-agents) |
    [tweet](https://twitter.com/ShunyuYao12/status/1699396834983362690)


- **InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback** <br>
    John Yang, Akshara Prabhakar, Karthik Narasimhan, Shunyu Yao <br>
    NeurIPS 2023 Datasets and Benchmarks Track <br>
    [paper](https://arxiv.org/abs/2306.14898) |
    [repo](https://github.com/princeton-nlp/intercode) |
    [tweet](https://twitter.com/ShunyuYao12/status/1675903408727896066) |
    [project](https://intercode-benchmark.github.io)
  
- **Reflexion: Language Agents with Verbal Reinforcement Learning** <br>
    Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao <br>
    NeurIPS 2023 <br>
    [paper](https://arxiv.org/abs/2303.11366) |
    [repo](https://github.com/noahshinn024/reflexion) |
    [tweet](https://twitter.com/ShunyuYao12/status/1661875632387641345)

- **Tree of Thoughts: Deliberate Problem Solving with Large Language Models** <br>
    Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan <br>
    NeurIPS 2023 (Oral) <br>
    [paper](https://arxiv.org/abs/2305.10601) |
    [repo](https://github.com/ysymyth/tree-of-thought-llm) |
    [tweet](https://twitter.com/ShunyuYao12/status/1659357547474681857)
    
- **ReAct: Synergizing Reasoning and Acting in Language Models** <br>
    Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao <br>
    ICLR 2023 (Oral, top 5%) <br>
    [paper](https://arxiv.org/abs/2210.03629) |
    [repo](https://github.com/ysymyth/ReAct) |
    [tweet](https://twitter.com/ShunyuYao12/status/1579475607402217472) |
    [project](https://react-lm.github.io) |
    [Google AI blogpost](https://ai.googleblog.com/2022/11/react-synergizing-reasoning-and-acting.html)
    
- **WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents** <br>
    Shunyu Yao\*, Howard Chen\*, John Yang, Karthik Narasimhan <br>
    NeurIPS 2022 <br>
    [paper](https://arxiv.org/abs/2207.01206) | 
    [repo](https://github.com/princeton-nlp/WebShop) | 
    [tweet](https://twitter.com/ShunyuYao12/status/1546220013186596864) |
    [project](https://webshop-pnlp.github.io) | 
    [demo](https://webshop-pnlp.github.io/#demo) |
    [Quanta Magazine](https://www.quantamagazine.org/machines-learn-better-if-we-teach-them-the-basics-20230201/)


# Favorite talks
- [Language Agents: From Next-Token Prediction to Digital Automation](https://www.youtube.com/watch?v=zwfE6J2BIR4)
- [On Formulating and Evaluating Language Agents](https://www.youtube.com/watch?v=qmGu9okiICU) 
- [从语言模型到语言智能体](https://www.bilibili.com/video/BV1ju4y1e7Em)
- [Re-thinking Reinforcement Learning in the Era of Large Language Models](https://docs.google.com/presentation/d/1mlhFBRdzN3aXQ1kDCwxGFfnQdjnHr7Ou9DAhLk186Y0/edit?usp=sharing&resourcekey=0-MVtkY5wr6GD-Dm80Cvsruw)


# Recent readings
* The Double Helix (James Watson)
* Lectures on General Relativity (David Tong)
* What Babies Know (Elizabeth Spelke)
* The Art of Doing Science and Engineering (Richard Hamming)

(last updated: Apr 2025)
