---
layout: default
title: Home
---

We are a research team at Alibaba Cloud. 

<!--Previously, I obtained my PhD from Princeton University advised by [Karthik Narasimhan](https://www.cs.princeton.edu/~karthikn/), and my bachelor's from Yao Class at Tsinghua University.
-->
I study agents.

<!--
In my work, I study agents.

In my life, I read, travel, rap, and play basketball.
-->
<!-- - To anyone: give me [feedback](https://www.admonymous.co/ysymyth) about anything! -->

<!--I dedicate 30 minutes per week to chat with students. Just paper plane me!  -->


<!---
# Recent News
- Sep 2023: Excited to release 🐨[CoALA](https://arxiv.org/abs/2309.02427), a systematic framework for language agents! Summary [here](https://twitter.com/ShunyuYao12/status/1699396834983362690).
- Aug 2023: I gave a [talk](https://www.bilibili.com/video/BV1ju4y1e7Em) in Chinese about ReAct, Reflexion, ToT, WebShop, InterCode, Collie. Slides [here](https://ysymyth.github.io/papers/from_language_models_to_language_agents.pdf).
- Jul 2023: I enjoyed teaching at [Princeton AI4ALL](https://ai4all.princeton.edu)! Coverage [here](https://www.today.com/video/how-the-summer-program-ai4all-is-helping-reshape-the-future-189707845651).
- Jul 2023: I wrote a [blog post](https://princeton-nlp.github.io/language-agent-impact/) with Karthik about opportunities and risks of language agents! Comment [here](https://twitter.com/ShunyuYao12/status/1683827766104408066).
<!---- Apr 2023: I attended LangChain's Agent [webinar](https://www.youtube.com/watch?v=1gRlCjy18m4). Summary [here](https://twitter.com/jh_damm/status/1646233627661828109).   --> 

# Selected work

- **Computer-Using Agent (CUA)** <br>
  OpenAI <br>
  A universal agent/interface to interact with the digital world. <br>
    [product](https://operator.chatgpt.com) |
    [blogpost](https://openai.com/index/computer-using-agent/) |
    [system card](https://cdn.openai.com/operator_system_card.pdf) |
    [bibtex](http://cdn.openai.com/cua/cua2025.bib)



- **Deep Research** <br>
  OpenAI <br>
  An agent that navigates and reasons over the Internet to research for you. <br>
    [product](https://chatgpt.com) |
    [blogpost](https://openai.com/index/introducing-deep-research/) 

  
- **τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains** <br>
  Shunyu Yao, Noah Shinn, Pedram Razavi, Karthik Narasimhan <br>
  ICLR 2025 <br>
    [paper](https://arxiv.org/abs/2406.12045) |
    [repo](https://github.com/sierra-research/tau-bench) |
    [blog](https://sierra.ai/blog/benchmarking-ai-agents)

- **Language Agents: From Next-Token Prediction to Digital Automation** <br>
  Shunyu Yao <br>
  PhD Thesis <br>
    [paper](https://ysymyth.github.io/papers/Dissertation-finalized.pdf) |
    [slides](https://ysymyth.github.io/papers/fpo.pdf) |
    [talk](https://www.youtube.com/watch?v=zwfE6J2BIR4)

- **SWE-agent: Agent Computer Interfaces Enable Software Engineering Language Models** <br>
  John Yang\*, Carlos E. Jimenez\*, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, Ofir Press <br>
  NeurIPS 2024 <br>
    [paper](https://swe-agent.com/paper.pdf) |
    [repo](https://github.com/princeton-nlp/SWE-agent) |
    [tweet](https://twitter.com/jyangballin/status/1775114444370051582) |
    [project](http://www.swe-agent.com)
  

- **SWE-bench: Can Language Models Resolve Real-World Github Issues?** <br>
  Carlos E. Jimenez\*, John Yang\*, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, Karthik Narasimhan <br>
  ICLR 2024 (Oral) <br>
    [paper](https://arxiv.org/abs/2310.06770) |
    [repo](https://github.com/princeton-nlp/SWE-bench) |
    [tweet](https://twitter.com/jyangballin/status/1711822353473437953) |
    [project](http://www.swebench.com)

- **Cognitive Architectures for Language Agents** <br>
    Shunyu Yao\*, Theodore Sumers\*, Karthik Narasimhan, Thomas L. Griffiths <br>
    TMLR 2024 <br>
    [paper](https://arxiv.org/abs/2309.02427) |
    [repo](https://github.com/ysymyth/awesome-language-agents) |
    [tweet](https://twitter.com/ShunyuYao12/status/1699396834983362690)

    
<!--- **Embers of Autoregression: Understanding Large Language Models Through the Problem They are Trained to Solve** <br>
    R. Thomas McCoy, Shunyu Yao, Dan Friedman, Matthew Hardy, Thomas L. Griffiths <br>
    [paper](https://arxiv.org/abs/2309.13638) |
    [repo](https://github.com/tommccoy1/embers-of-autoregression) |
    [tweet](https://twitter.com/RTomMcCoy/status/1706664506913399198)
   -->

<!---- **Referral Augmentation for Zero-Shot Information Retrieval** <br>
    Michael Tang, Shunyu Yao, John Yang, Karthik Narasimhan <br>
    [paper](https://arxiv.org/abs/2305.15098) |
    [repo](https://github.com/michaelwilliamtang/referral-augment) |
    [tweet](https://twitter.com/ShunyuYao12/status/1661340889724100611)
   -->
   
<!-- - **Collie: Systematic Construction of Constrained Text Generation Tasks** <br>
    Shunyu Yao\*, Howard Chen\*, Austin Wang\*, Runzhe Yang\*, Karthik Narasimhan <br>
    [paper](https://arxiv.org/abs/2307.08689) |
    [repo](https://github.com/princeton-nlp/Collie) |
    [tweet](https://twitter.com/ShunyuYao12/status/1681315647018663936) |
    [project](https://collie-benchmark.github.io)
   -->
- **InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback** <br>
    John Yang, Akshara Prabhakar, Karthik Narasimhan, Shunyu Yao <br>
    NeurIPS 2023 Datasets and Benchmarks Track <br>
    [paper](https://arxiv.org/abs/2306.14898) |
    [repo](https://github.com/princeton-nlp/intercode) |
    [tweet](https://twitter.com/ShunyuYao12/status/1675903408727896066) |
    [project](https://intercode-benchmark.github.io)
  
- **Reflexion: Language Agents with Verbal Reinforcement Learning** <br>
    Noah Shinn, Federico Cassano, Beck Labash, Ashwin Gopinath, Karthik Narasimhan, Shunyu Yao <br>
    NeurIPS 2023 <br>
    [paper](https://arxiv.org/abs/2303.11366) |
    [repo](https://github.com/noahshinn024/reflexion) |
    [tweet](https://twitter.com/ShunyuYao12/status/1661875632387641345)

- **Tree of Thoughts: Deliberate Problem Solving with Large Language Models** <br>
    Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan <br>
    NeurIPS 2023 (Oral) <br>
    [paper](https://arxiv.org/abs/2305.10601) |
    [repo](https://github.com/ysymyth/tree-of-thought-llm) |
    [tweet](https://twitter.com/ShunyuYao12/status/1659357547474681857)
    
- **ReAct: Synergizing Reasoning and Acting in Language Models** <br>
    Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao <br>
    ICLR 2023 (Oral, top 5%) <br>
    [paper](https://arxiv.org/abs/2210.03629) |
    [repo](https://github.com/ysymyth/ReAct) |
    [tweet](https://twitter.com/ShunyuYao12/status/1579475607402217472) |
    [project](https://react-lm.github.io) |
    [Google AI blogpost](https://ai.googleblog.com/2022/11/react-synergizing-reasoning-and-acting.html)
    
- **WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents** <br>
    Shunyu Yao\*, Howard Chen\*, John Yang, Karthik Narasimhan <br>
    NeurIPS 2022 <br>
    [paper](https://arxiv.org/abs/2207.01206) | 
    [repo](https://github.com/princeton-nlp/WebShop) | 
    [tweet](https://twitter.com/ShunyuYao12/status/1546220013186596864) |
    [project](https://webshop-pnlp.github.io) | 
    [demo](https://webshop-pnlp.github.io/#demo) |
    [Quanta Magazine](https://www.quantamagazine.org/machines-learn-better-if-we-teach-them-the-basics-20230201/)

<!-- - **TVShowGuess: Character Comprehension in Stories as Speaker Guessing** <br>
    Yisi Sang\*, Xiangyang Mou\*, Mo Yu\*, Shunyu Yao, Jing Li, Jeffrey Stanton <br>
    NAACL 2022 <br>
    [paper](https://arxiv.org/abs/2204.07721)  | 
    [code](https://github.com/YisiSang/TVSHOWGUESS)
 -->

<!-- - **Linking Emergent and Natural Languages via Corpus Transfer** <br>
    Shunyu Yao, Mo Yu, Yang Zhang, Karthik Narasimhan, Joshua Tenenbaum, Chuang Gan <br>
    ICLR 2022 (Spotlight) <br>
    [paper](http://arxiv.org/abs/2203.13344) | 
    [code](https://github.com/ysymyth/ec-nl) |
    [tweet](https://twitter.com/ShunyuYao12/status/1518774718639181824)
 -->
<!-- 
- **Multi-Stage Episodic Control for Strategic Exploration in Text Games** <br>
    Jens Tuyls, Shunyu Yao, Sham Kakade, Karthik Narasimhan <br>
    ICLR 2022 (Spotlight) <br>
    [paper](https://arxiv.org/abs/2201.01251) | 
    [code](https://github.com/princeton-nlp/XTX) | 
    [project](https://sites.google.com/princeton.edu/xtx)

 -->
<!--  - **Self-Attention Networks Can Process Bounded Hierarchical Languages** <br>
    Shunyu Yao, Binghui Peng, Christos Papadimitriou, Karthik Narasimhan <br>
    ACL 2021 <br>
    [paper](https://arxiv.org/abs/2105.11115) | 
    [code](https://github.com/princeton-nlp/dyck-transformer) |
    [tweet](https://twitter.com/ShunyuYao12/status/1397047887763099650) | 
    [AI2 NLP Highlights Podcast](https://soundcloud.com/nlp-highlights/129-transformers-and-hierarchical-structure-with-shunyu-yao?utm_source=allenai.org&utm_campaign=wtshare&utm_medium=widget&utm_content=https%253A%252F%252Fsoundcloud.com%252Fnlp-highlights%252F129-transformers-and-hierarchical-structure-with-shunyu-yao) -->
    

<!--  - **Reading and Acting while Blindfolded: The Need for Semantics in Text Game Agents** <br>
    Shunyu Yao, Karthik Narasimhan, Matthew Hausknecht <br>
    NAACL 2021 <br>
    [paper](https://arxiv.org/abs/2103.13552) | 
    [code](https://github.com/princeton-nlp/blindfold-textgame) |
    [project](https://blindfolded.cs.princeton.edu) | 
    [Microsoft Research blogpost](https://www.microsoft.com/en-us/research/blog/building-stronger-semantic-understanding-into-text-game-reinforcement-learning-agents/) -->

<!-- - **Keep CALM and Explore: Language Models for Action Generation in Text-based Games** <br>
    Shunyu Yao, Rohan Rao, Matthew Hausknecht, Karthik Narasimhan <br>
    EMNLP 2020 <br>
    [paper](https://arxiv.org/abs/2010.02903) | 
    [code](https://github.com/princeton-nlp/calm-textgame) | 
    [tweet](https://twitter.com/ShunyuYao12/status/1316083890604388353)  -->

<!-- - **The Fine Structure of Surprise in Intuitive Physics: When, Why, and How Much?** <br>
    Kevin Smith, Lingjie Mei, Shunyu Yao, Jiajun Wu, Elizabeth Spelke, Joshua Tenenbaum, Tomer Ullman <br>
    CogSci 2020 <br>
    [paper](https://ysymyth.github.io/papers/surprise_cogsci.pdf)

- **Modeling Expectation Violation in Intuitive Physics with Coarse Probabilistic Object Representations** <br>
    Kevin Smith\*, Lingjie Mei\*, Shunyu Yao\*, Jiajun Wu, Elizabeth Spelke, Joshua Tenenbaum, Tomer Ullman <br>
    NeurIPS 2019 <br>
    [paper](http://papers.neurips.cc/paper/9100-modeling-expectation-violation-in-intuitive-physics-with-coarse-probabilistic-object-representations.pdf) | 
    [code](https://github.com/JerryLingjieMei/ADEPT-Model-Release) | 
    [data](https://github.com/JerryLingjieMei/ADEPT-Dataset-Release) |
    [project](http://physadept.csail.mit.edu) | 
    [MIT news](http://news.mit.edu/2019/adept-ai-machines-laws-physics-1202)
 -->
<!-- - **3D-aware Scene Manipulation via Inverse Graphics** <br>
    Shunyu Yao\*, Tzu-Ming Harry Hsu\*, Jun-Yan Zhu, Jiajun Wu, Antonio Torralba, William Freeman, Joshua Tenenbaum <br>
    NeurIPS 2018 <br>
    [paper](https://arxiv.org/abs/1808.09351) | 
    [code](https://github.com/ysymyth/3D-SDN) | 
    [project](http://3dsdn.csail.mit.edu) -->


# Online talks
- [Language Agents: From Next-Token Prediction to Digital Automation](https://www.youtube.com/watch?v=zwfE6J2BIR4)
- [On Formulating and Evaluating Language Agents](https://www.youtube.com/watch?v=qmGu9okiICU) 
- [从语言模型到语言智能体](https://www.bilibili.com/video/BV1ju4y1e7Em)
- [Re-thinking Reinforcement Learning in the Era of Large Language Models](https://docs.google.com/presentation/d/1mlhFBRdzN3aXQ1kDCwxGFfnQdjnHr7Ou9DAhLk186Y0/edit?usp=sharing&resourcekey=0-MVtkY5wr6GD-Dm80Cvsruw)


# Recent readings
* The Double Helix (James Watson)
* Lectures on General Relativity (David Tong)
* What Babies Know (Elizabeth Spelke)
* The Art of Doing Science and Engineering (Richard Hamming)


<!--   
* Advice for a Young Investigator (Santiago Cajal)
* The Worlds I See (Fei-fei Li)
* Einstein: His Life and Universe (Walter Isaacson)
* Set Theory (John Burgess)
* The Computer and the Brain (John von Neumann)
* Automata Studies (Editted by C.E. Shannon and J. McCarthy)
* Team of Rivals (Doris Goodwin)
* The Linguistics Wars (Randy Harris)
 -->
<!-- * A Simpler Life (The School of Life)
* Elon Musk (Walter Isaacson)
* The Search (John Battelle) -->
<!-- * Leadership: In Turbulent Times (Doris Kearns Goodwin) -->
<!-- * 置身事内 （兰小欢） -->
<!-- * The Linguistics Wars (Randy Allen Harris) -->
<!-- * Antoni Gaudí（dosde）-->
<!-- * 西方语言学史 （姚小平）-->


(last updated: Feb 2025)
